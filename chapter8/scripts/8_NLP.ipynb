{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:40:45.485421Z",
     "start_time": "2019-07-14T15:40:33.119220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77273, 8)      团购活动ID       用户ID     用户名                 评价时间                      评价内容  \\\n",
      "0  10051080  437407990  嗯****～  2018-04-04 08:35:30          这家店竟然没有玉米饼和杠子馍。。   \n",
      "1  10051080  434997839  露****4  2017-10-25 08:18:22           味道很不错，今天还要再去，很棒   \n",
      "2  10051080  424757158  礼****来  2017-01-19 02:38:39      很划算，适合5、6个人吃不浪费，很喜欢！   \n",
      "3  10051080  424646918  请****7  2017-01-17 09:15:15           味道不错，喜欢吃肉的朋友可以去   \n",
      "4  10051080  423190677  1****0  2016-12-26 01:43:18  环境优雅，爱吃肉的朋友可以去体验一下，味道不错！   \n",
      "\n",
      "   评分         消费门店   用户排名  \n",
      "0   4  姥家大锅台(交通路店)  10161  \n",
      "1   5  姥家大锅台(交通路店)   9681  \n",
      "2   5  姥家大锅台(交通路店)   8847  \n",
      "3   5  姥家大锅台(交通路店)   8835  \n",
      "4   5  姥家大锅台(交通路店)   8772  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 导入数据\n",
    "path = r\"../data/\"\n",
    "origin_file = \"comment_nm.xlsx\"\n",
    "comments_df = pd.read_excel(os.path.join(path, origin_file), encoding=\"utf8\")\n",
    "comments_df.shape\n",
    "print(comments_df.shape, comments_df.head())\n",
    "# 留个备份, 这样之后覆盖写错了就不用重新覆盖\n",
    "comments_df2 = comments_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:40:45.709422Z",
     "start_time": "2019-07-14T15:40:45.619422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58117"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. 清洗数据, 删除空的数据\n",
    "def clean_sents(txt):\n",
    "    txt = str(txt) if txt is not None else \"\"\n",
    "    if len(txt) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return txt\n",
    "\n",
    "comments_df2[\"评价内容\"] = comments_df2[\"评价内容\"].apply(clean_sents)\n",
    "comments_df2 = comments_df2[comments_df2[\"评价内容\"] != \"nan\"]\n",
    "len(comments_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:40:47.270420Z",
     "start_time": "2019-07-14T15:40:45.832424Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. 引入停用词文本\n",
    "import jieba\n",
    "\n",
    "stopwords_file = \"stopwords.txt\"\n",
    "with open(os.path.join(path, stopwords_file), \"r\", encoding=\"utf8\") as f:\n",
    "    stopwords_list = [word.strip() for word in f.read()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:41:30.852153Z",
     "start_time": "2019-07-14T15:40:47.365422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\jieba.cache\n",
      "Loading model cost 1.077 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>团购活动ID</th>\n",
       "      <th>用户ID</th>\n",
       "      <th>用户名</th>\n",
       "      <th>评价时间</th>\n",
       "      <th>评价内容</th>\n",
       "      <th>评分</th>\n",
       "      <th>消费门店</th>\n",
       "      <th>用户排名</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10051080</td>\n",
       "      <td>437407990</td>\n",
       "      <td>嗯****～</td>\n",
       "      <td>2018-04-04 08:35:30</td>\n",
       "      <td>[这家, 店, 竟然, 没有, 玉米饼, 杠子, 馍]</td>\n",
       "      <td>4</td>\n",
       "      <td>姥家大锅台(交通路店)</td>\n",
       "      <td>10161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10051080</td>\n",
       "      <td>434997839</td>\n",
       "      <td>露****4</td>\n",
       "      <td>2017-10-25 08:18:22</td>\n",
       "      <td>[味道, 很, 不错, 今天, 还要, 去, 很棒]</td>\n",
       "      <td>5</td>\n",
       "      <td>姥家大锅台(交通路店)</td>\n",
       "      <td>9681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10051080</td>\n",
       "      <td>424757158</td>\n",
       "      <td>礼****来</td>\n",
       "      <td>2017-01-19 02:38:39</td>\n",
       "      <td>[很, 划算, 适合, 个人, 吃, 浪费, 很, 喜欢]</td>\n",
       "      <td>5</td>\n",
       "      <td>姥家大锅台(交通路店)</td>\n",
       "      <td>8847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10051080</td>\n",
       "      <td>424646918</td>\n",
       "      <td>请****7</td>\n",
       "      <td>2017-01-17 09:15:15</td>\n",
       "      <td>[味道, 不错, 喜欢, 吃, 肉, 朋友, 可以, 去]</td>\n",
       "      <td>5</td>\n",
       "      <td>姥家大锅台(交通路店)</td>\n",
       "      <td>8835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10051080</td>\n",
       "      <td>423190677</td>\n",
       "      <td>1****0</td>\n",
       "      <td>2016-12-26 01:43:18</td>\n",
       "      <td>[环境, 优雅, 爱, 吃, 肉, 朋友, 可以, 去, 体验, 一下, 味道, 不错]</td>\n",
       "      <td>5</td>\n",
       "      <td>姥家大锅台(交通路店)</td>\n",
       "      <td>8772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     团购活动ID       用户ID     用户名                 评价时间  \\\n",
       "0  10051080  437407990  嗯****～  2018-04-04 08:35:30   \n",
       "1  10051080  434997839  露****4  2017-10-25 08:18:22   \n",
       "2  10051080  424757158  礼****来  2017-01-19 02:38:39   \n",
       "3  10051080  424646918  请****7  2017-01-17 09:15:15   \n",
       "4  10051080  423190677  1****0  2016-12-26 01:43:18   \n",
       "\n",
       "                                           评价内容  评分         消费门店   用户排名  \n",
       "0                   [这家, 店, 竟然, 没有, 玉米饼, 杠子, 馍]   4  姥家大锅台(交通路店)  10161  \n",
       "1                    [味道, 很, 不错, 今天, 还要, 去, 很棒]   5  姥家大锅台(交通路店)   9681  \n",
       "2                 [很, 划算, 适合, 个人, 吃, 浪费, 很, 喜欢]   5  姥家大锅台(交通路店)   8847  \n",
       "3                 [味道, 不错, 喜欢, 吃, 肉, 朋友, 可以, 去]   5  姥家大锅台(交通路店)   8835  \n",
       "4  [环境, 优雅, 爱, 吃, 肉, 朋友, 可以, 去, 体验, 一下, 味道, 不错]   5  姥家大锅台(交通路店)   8772  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def filter_stopwords(txt):\n",
    "    \"\"\"过滤停用词\"\"\"\n",
    "    sent = jieba.lcut(txt)\n",
    "    words = []\n",
    "    for word in sent:\n",
    "        word = word.strip()\n",
    "        if(word in stopwords_list):\n",
    "            continue\n",
    "        else:\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "comments_df2[\"评价内容\"] = comments_df2[\"评价内容\"].apply(filter_stopwords)\n",
    "comments_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:41:34.391174Z",
     "start_time": "2019-07-14T15:41:31.049153Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. 切分训练集和验证集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(comments_df2[\"评价内容\"], comments_df2[\"评分\"], test_size=0.3)\n",
    "val_X, test_X, val_y, test_y = train_test_split(val_X, val_y, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:41:39.350147Z",
     "start_time": "2019-07-14T15:41:34.585169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('很', 23350),\n",
       " ('不错', 21834),\n",
       " ('味道', 17218),\n",
       " ('吃', 15025),\n",
       " ('好吃', 11842),\n",
       " ('环境', 9027),\n",
       " ('服务', 9025),\n",
       " ('去', 9000),\n",
       " ('可以', 7723),\n",
       " ('都', 7231)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 统计词频\n",
    "from nltk import FreqDist\n",
    "\n",
    "all_words = []\n",
    "for comment in comments_df2[\"评价内容\"]:\n",
    "    all_words.extend(comment)\n",
    "\n",
    "len(all_words)\n",
    "\n",
    "fdisk = FreqDist(all_words)\n",
    "TOP_COMMON_WORDS = 1000\n",
    "most_common_words = fdisk.most_common(TOP_COMMON_WORDS)\n",
    "most_common_words[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:41:51.506190Z",
     "start_time": "2019-07-14T15:41:39.657149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19247589d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 生成前N个高频词的词云\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "mask = np.array(Image.open(os.path.join(path, \"火锅图片.png\")))\n",
    "wc = WordCloud(font_path=os.path.join(path, \"simkai.ttf\"),\n",
    "               background_color=\"white\",\n",
    "               contour_width=3,\n",
    "               contour_color='steelblue',\n",
    "               mask=mask,\n",
    "               width=1000,\n",
    "               height=1000)\n",
    "\n",
    "wc.generate_from_frequencies(dict(most_common_words))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(os.path.join(path, \"火锅词云.png\"), dpi=1000)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:45:23.001909Z",
     "start_time": "2019-07-14T15:44:41.659916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经完成0个样本的特征提取.\n",
      "已经完成5000个样本的特征提取.\n",
      "已经完成10000个样本的特征提取.\n",
      "已经完成15000个样本的特征提取.\n",
      "已经完成20000个样本的特征提取.\n",
      "已经完成25000个样本的特征提取.\n",
      "已经完成30000个样本的特征提取.\n",
      "已经完成35000个样本的特征提取.\n",
      "已经完成40000个样本的特征提取.\n",
      "已经完成0个样本的特征提取.\n",
      "已经完成5000个样本的特征提取.\n"
     ]
    }
   ],
   "source": [
    "# 生成TF-IDF和词袋模型\n",
    "# TODO 用nltk调用tf-idf\n",
    "from nltk.text import TextCollection\n",
    "\n",
    "tfidf_generator = TextCollection(comments_df2[\"评价内容\"].values.tolist())\n",
    "\n",
    "def extract_tfidf(texts, targets, text_collection, common_words):\n",
    "    \"\"\"\n",
    "    提取文本的tf-idf.\n",
    "        texts: 输入的文本.\n",
    "        targets: 对应的评价.\n",
    "        text_collection: 预先初始化的TextCollection.\n",
    "        common_words: 输入的前N个词作为特征进行计算.\n",
    "    \"\"\"\n",
    "    # 得到行向量的维度\n",
    "    n_sample = len(texts)\n",
    "    # 得到列向量的维度\n",
    "    n_feat = len(common_words)\n",
    "\n",
    "    # 初始化X矩阵, X为最后要输出的TF-IDF矩阵\n",
    "    X = np.zeros([n_sample, n_feat])\n",
    "    y = np.zeros(n_sample)\n",
    "    for i, text in enumerate(texts):\n",
    "        if i % 5000 == 0:\n",
    "            print(\"已经完成{}个样本的特征提取.\".format(i))\n",
    "\n",
    "        # 每一行对应一个文档, 计算这个文档中的词的tf-idf, 没出现的词则为0\n",
    "        feature_vector = []\n",
    "        for word in common_words:\n",
    "            if word in text:\n",
    "                tf_idf = text_collection.tf_idf(word, text)\n",
    "            else:\n",
    "                tf_idf = 0.0\n",
    "\n",
    "            feature_vector.append(tf_idf)\n",
    "\n",
    "        X[i, :] = np.array(feature_vector)\n",
    "        y[i] = targets.iloc[i]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "cleaned_train_X, cleaned_train_y = extract_tfidf(train_X, train_y, tfidf_generator, dict(most_common_words).keys())\n",
    "cleaned_val_X, cleaned_val_y = extract_tfidf(val_X, val_y, tfidf_generator, dict(most_common_words).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
